# ğŸ” SecureAI â€“ Red & Blue Teaming on MNIST

## ğŸ“Œ Project Overview
This project demonstrates **Threat Modeling, Adversarial Attacks, Data Poisoning, SAST Analysis, and Defense Training** on a CNN trained using the MNIST dataset. It is submitted as part of the **Secure AI Systems Assignment**.

## ğŸš€ Features Implemented
âœ” Train CNN Model on MNIST  
âœ” Evaluate model performance (accuracy, loss, confusion matrix)  
âœ” Data Poisoning (100 images with digit â€˜7â€™)  
âœ” Train model on poisoned dataset  
âœ” Defense model training using adversarial + clean data  
âœ” Generate adversarial samples using FGSM  
âœ” Defense and re-evaluation of model  

---

## ğŸ“‚ Project Structure

SecureAI/
â”‚â”€â”€ cnn_model/
â”‚ â”œâ”€â”€ train.py
â”‚ â”œâ”€â”€ train_with_poison.py
â”‚ â”œâ”€â”€ train_defense.py
â”‚â”€â”€ adversarial/
â”‚ â”œâ”€â”€ poison_dataset.py
â”‚â”€â”€ data/ â† MNIST dataset (.idx files)
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md


---

## ğŸ§ª Training Commands

### ğŸ’» Train Baseline Model (Clean Dataset)
python cnn_model/train.py

â˜  Train Poisoned Model :
python cnn_model/train_with_poison.py

ğŸ›¡ Train Defense Model :
python cnn_model/train_defense.py

ğŸ“Š Final Performance Summary :
Model	Accuracy	Loss
Baseline (Clean)	99.2%	0.032
Poisoned Model	99.1%	0.0314
Defense Model	98.7%	0.048

ğŸ” Threat Modeling (STRIDE) :
We have performed threat analysis using STRIDE â€” the document is available in
ğŸ‘‰ Threat_Model_STRIDE.md 

ğŸ“Œ Final Report
All results, screenshots, and metrics are included in:
ğŸ‘‰ Report_SecureAI.pdf




ğŸ‘©â€ğŸ’» Name: Mangamuri Venkata Pranathi 

ğŸ“§ Email: cs23btech11034@iith.ac.in

