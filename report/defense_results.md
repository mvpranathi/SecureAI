## Defense Model Performance (After Blue Team Protection)

| Metric | Value |
|--------|-------|
| Defense Accuracy | **0.9876999855041504** |
| Defense Loss | **0.0482485368847847** |

### üîç Observations:
- After applying adversarial defense techniques (training with both clean + poisoned data),  
  the model **recovered strongly** even after poisoning.
- Accuracy slightly decreased compared to original model,  
  but **the model became more robust** against attacks.
- This proves that **adversarial training improves security** of AI systems.
